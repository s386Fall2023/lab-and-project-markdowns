---
title: "Project "
layout: single
author_profile: false
classes: wide
# excerpt: 
---
# Semester Project 



There are five levels or tiers available for you complete the semester project.  Each tier offers varying levels of complexity and deliverables.  Your chosen tier will guide the expectations for your project, allowing you to decide the level of challenge you wish to undertake.  A semester project of at least Tier 5 is required in order to pass the class. 
* [Tier 1: Leader](#tier-1)
* [Tier 2: Between Leader and Contributor](#tier-2)
* [Tier 3: Contributor](#tier-3)
* [Tier 4: Observer](#tier-4)
* [Tier 5: Disengaged](#tier-5)

Each project tier has the same general parts:
1. Pose a question that can by answered or better understood by exploring data
2. Collect data for an original dataset and clean it into a tidy dataset
3. Perform an EDA on the data
4. Present your data or a summary of your data

---
---
## Tier 1:

#### Part 1: Choose a topic
* Choose a topic both of interest to you and of general interest
* Pose a related research question:
    * that is original, creative, compelling and not overly trivial  
    * that can be answered and explored using data
* **TASKS:**
    - [ ] Brainstorm topics and related questions 
    - [ ] Get feedback from fellow students about (a) general interest, (b) creativity / originality and (c) scope of the topic and related question
    - [ ] Choose a final topic and related question
    - [ ] Document the feedback process and how it improved the general interest, scope and originality of your final topic (include in the `feedback` folder of the repo - see part 2)

#### Part 2: Data collection and cleaning
* Collect publicly available data into an original dataset.  
* **REQUIREMENTS** 
    - [ ] Data should be assembled by querying one or more APIs and/or web scraping using BeautifulSoup and/or Selenium (using multiple sources is encouraged)
    - [ ] All work must be done in Python
    - [ ] Data should have AT LEAST:
        * 500 observations 
        * 8 informative features (e.g., an "ID" column would not generally be considered informative)
        * Two features that are numeric
        * Two features that are categorical
    - [ ] Data should be comprehensive enough for a detailed EDA and future predictive model 
* **TASKS**
    - [ ] Assemble the dataset according to the requirements above
    - [ ] Create a public GitHub repository that includes:
        * Your python code for scraping and cleaning (*Remember not to include any private api or authentication keys*)
        * Your dataset (*If there is a privacy or other reason that your data should not be included in the repo, please talk to me*)
        * A Readme.md file explaining the purpose and contents of the repo
        * A folder called `feedback` that contains the documentation of the peer feedback and your response to the feedback for each part of the project
    - [ ] Write a blog post that includes:
        * Introduction and motivation for the topic/question
        * Description of how data was collected and cleaned
        * Explanation of how you determined/ensured the ethicalness of your web scraping
        * Conclusion 
    - [ ] Get feedback from classmates or others about the quality of your blog post
    - [ ] Edit your blog post based on the feedback received 
    - [ ] Document the feedback process including how your blog post was improved based on the feedback you received 


#### Part 3: Exploratory Data Analysis
* Perform and exploratory data analysis of your dataset 
* **REQUIREMENTS**
* **TASKS**
EDA of a dataset (preferably the data you collected for the last project) and write a blog post about the highlights of your EDA.   

You should do a preliminary EDA of a dataset (preferably the data you scraped from the previous mini-project).  You should report the highlights of your EDA in a blog post.  

Your blog post should have the following:

An informative title and brief description
An introduction.  Briefly introduce your project.  Don't repeat verbatim the intro from your previous post, but don't just refer to the previous post without any intro.  You can refer to the previous post, but still keep the current post self contained.
5ish - 10ish figures and tables that give the reader a feel for your data with a few sentences of interpretation or explanation 
A conclusion with your main findings and a hint of the story of the data
Also, you should update the GitHub repository that contains the work for this project.  If you are using new data, then create a new repository with the relevant files.  Include a link to your GitHub repo in your blog post. 


## Tier 2

## Tier 3

## Tier 4


## Tier 5
1. Choose a topic of interest
2. Find a publicly available dataset related to your to your topic (for example, a dataset available on Kaggle).  
* The data should have at least 200 observations and 5 features where at least one is a numeric feature
* If the dataset requires very little additional wrangling/cleaning then it likely will not meet the standards of a higher tier
3. Perform a simple EDA of the chosen dataset with at least 4 graphics
4. Submit a brief report outlining your topic, methods, and findings


